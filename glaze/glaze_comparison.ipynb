{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebd3b228",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 16:17:38.838354: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# --- IMPORTAZIONI ---\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from numpy.fft import fft2, fftshift\n",
    "import cv2\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f1acb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FUNZIONI UTILI ---\n",
    "def load_and_preprocess_image(img_path):\n",
    "    img = keras_image.load_img(img_path, target_size=(512, 512))\n",
    "    img_array = keras_image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    return img_array\n",
    "\n",
    "def load_feature_extractor():\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(512, 512, 3))\n",
    "    model = Model(inputs=base_model.input, outputs=base_model.get_layer('block5_conv3').output)\n",
    "    return model\n",
    "\n",
    "def extract_features(img, model):\n",
    "    features = model.predict(img, verbose=0)\n",
    "    return features.flatten()\n",
    "\n",
    "def compute_metrics(original, cloaked):\n",
    "    orig = ((original[0] + 1) / 2).clip(0, 1)\n",
    "    cloak = ((cloaked[0] + 1) / 2).clip(0, 1)\n",
    "    psnr_val = psnr(orig, cloak, data_range=1.0)\n",
    "    ssim_val = ssim(orig, cloak, data_range=1.0, channel_axis=-1)\n",
    "    return psnr_val, ssim_val\n",
    "\n",
    "def show_images(img1, img2, title1=\"Originale\", title2=\"Cloaked\"):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].imshow(((img1[0] + 1) / 2).clip(0, 1))\n",
    "    axs[0].set_title(title1)\n",
    "    axs[0].axis('off')\n",
    "    axs[1].imshow(((img2[0] + 1) / 2).clip(0, 1))\n",
    "    axs[1].set_title(title2)\n",
    "    axs[1].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def show_difference_map(original, cloaked):\n",
    "    diff = np.abs(original[0] - cloaked[0])\n",
    "    diff /= diff.max()\n",
    "    plt.imshow(diff)\n",
    "    plt.title(\"Mappa delle differenze (assolute)\")\n",
    "    plt.axis('off')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "def show_fft(image, title):\n",
    "    gray = cv2.cvtColor(((image[0] + 1) / 2).astype(np.float32), cv2.COLOR_RGB2GRAY)\n",
    "    f = fft2(gray)\n",
    "    fshift = fftshift(f)\n",
    "    magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1e-8)\n",
    "    plt.imshow(magnitude_spectrum, cmap='gray')\n",
    "    plt.title(f\"Spettro FFT - {title}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00a9cd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 16:21:37.130306: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# --- CARICAMENTO IMMAGINI ---\n",
    "# Modifica i path con quelli corretti nel tuo PC\n",
    "original_path = \"Pikachu.png\"\n",
    "#your_cloaked_path = \"OutputLocker.png\"   # <-- salva qui la tua immagine cloakata\n",
    "glaze_low_path = \"Pikachu-protected-intensity-LOW-V2.png\"\n",
    "glaze_default_path = \"Pikachu-protected-intensity-DEFAULT-V2.png\"\n",
    "glaze_high_path = \"Pikachu-protected-intensity-HIGH-V2.png\"\n",
    "\n",
    "\n",
    "# Carica immagini\n",
    "original = load_and_preprocess_image(original_path)\n",
    "#your_cloaked = load_and_preprocess_image(your_cloaked_path)\n",
    "glaze_low = load_and_preprocess_image(glaze_low_path)\n",
    "glaze_default = load_and_preprocess_image(glaze_default_path)\n",
    "glaze_high = load_and_preprocess_image(glaze_high_path)\n",
    "\n",
    "# Carica modello\n",
    "model = load_feature_extractor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bc62c74",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'your_cloaked' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# --- ANALISI E VISUALIZZAZIONI ---\u001b[39;00m\n\u001b[1;32m      2\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m images \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m----> 4\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTuo Cloaked\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43myour_cloaked\u001b[49m),\n\u001b[1;32m      5\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGlaze LOW\u001b[39m\u001b[38;5;124m\"\u001b[39m, glaze_low),\n\u001b[1;32m      6\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGlaze DEFAULT\u001b[39m\u001b[38;5;124m\"\u001b[39m, glaze_default),\n\u001b[1;32m      7\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGlaze HIGH\u001b[39m\u001b[38;5;124m\"\u001b[39m, glaze_high)\n\u001b[1;32m      8\u001b[0m ]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Feature originale\u001b[39;00m\n\u001b[1;32m     11\u001b[0m features_original \u001b[38;5;241m=\u001b[39m extract_features(original, model)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'your_cloaked' is not defined"
     ]
    }
   ],
   "source": [
    "# --- ANALISI E VISUALIZZAZIONI ---\n",
    "results = []\n",
    "images = [\n",
    "    (\"Tuo Cloaked\", your_cloaked),\n",
    "    (\"Glaze LOW\", glaze_low),\n",
    "    (\"Glaze DEFAULT\", glaze_default),\n",
    "    (\"Glaze HIGH\", glaze_high)\n",
    "]\n",
    "\n",
    "# Feature originale\n",
    "features_original = extract_features(original, model)\n",
    "\n",
    "for name, img in images:\n",
    "    psnr_val, ssim_val = compute_metrics(original, img)\n",
    "    features_img = extract_features(img, model)\n",
    "    l2_distance = np.linalg.norm(features_original - features_img)\n",
    "\n",
    "    results.append({\n",
    "        \"Nome\": name,\n",
    "        \"PSNR (dB)\": psnr_val,\n",
    "        \"SSIM\": ssim_val,\n",
    "        \"L2 distance\": l2_distance\n",
    "    })\n",
    "\n",
    "    print(f\"üñºÔ∏è Analisi: {name}\")\n",
    "    show_images(original, img, \"Originale\", name)\n",
    "    show_difference_map(original, img)\n",
    "    show_fft(img, f\"FFT - {name}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de1b7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TABELLA RIASSUNTIVA FINALE ---\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.set_index(\"Nome\", inplace=True)\n",
    "display(df_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glaze-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
